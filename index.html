<!DOCTYPE html>
<html>
  <head>
    <title>Rob van Gastel</title>
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="favicon.ico" sizes="16x16">
  </head>
  <body>
    <div id="wrapper">
		<h1>Rob van Gastel</h1>
   		<p>As a machine learning engineer, I am passionate about meta-learning, particularly in combining it with visual self-supervised learning. I am interested in developing intelligent agents that can rapidly acquire new skills and adapt to novel environments with minimal supervision.</p>
		<p><a href="https://github.com/robvangastel" target="_blank">Github</a> / <a href="https://www.linkedin.com/in/rob-van-gastel-79bb14121/" target="_blank">LinkedIn</a> / <a href="https://twitter.com/robvgastel" target="_blank">Twitter</a></p>
		<br/>
		<p class="projects"><b>Research</b></p>
      <a href="https://openreview.net/forum?id=SZ4gZaBUl5" target="_blank"><p class="title">
        Regularized Meta-Learning for Neural Architecture Search
      </p></a>
      <p class="description">
        Rob van Gastel, <a href="https://joaquinvanschoren.github.io/" target="_blank">Joaquin Vanschoren</a></br>
        AutoML-Conf Late-Breaking Workshop 2022 </br>
        <a href="https://openreview.net/forum?id=SZ4gZaBUl5" target="_blank">paper</a> / <a href="https://github.com/RobvanGastel/meta-fsl-nas" target="_blank">code</a>
        <br/>
        We apply regularization techniques to the inner-loop neural architecture search to improve meta-learning, adapting to new tasks more quickly.
      </p>
    </br>
    <p class="projects"><b>Projects</b></p>
	  <p><a href="https://github.com/RobvanGastel/removing-pos-vit-bias" target="_blank">
        Removing Bias by Post-Training Pretrained Encoders
      </a></p>
      <p class="project-description">
		  Testing Franca's "Removal of Absolute Spatial Attributes" (RASA) post-training method to debias pretrained ViTs is simple and effective, and also works for other pretrained backbones like DINOv2 and DINOv3, improving downstream tasks with just one additional hour of training. 
	  </p>
      <p><a href="https://github.com/RobvanGastel/meta-in-context-learning" target="_blank">
        Exploring Meta In-Context Learning
      </a></p>
      <p class="project-description">
        Testing the mechanic that allows LLMs to adapt their predictions by using context, in-context learning, on a smaller scale. I test the capabilities of meta in-context learners to solve out-of-domain tasks.
      </p>
      <p><a href="https://github.com/RobvanGastel/dinov2-finetune" target="_blank">
        Finetuning Transferable Vision Transformer Weights
      </a></p>
      <p class="project-description">
        Finetuning the encoder weights of the self-supervised learning method DINOv2 using a simple 1x1 convolution encoder and Low-Rank Adaptation (LoRA) allows for adaptation to the Pascal VOC and ADE20k datasets within a few epochs.
      </p>
      <p><a href="https://github.com/RobvanGastel/meta-rl-algorithms" target="_blank">
        Meta-Reinforcement Learning Algorithms
      </a></p>
      <p class="project-description">
        Implementations of Meta-Reinforcement Learning algorithms designed to quickly adapt policies to new, related tasks within a few episodes. 
      </p>
	  </div>
  </body>
  <canvas></canvas>
  <script>
    document.addEventListener('touchmove', function (e) {
          e.preventDefault()
      })
      var c = document.getElementsByTagName('canvas')[0],
          x = c.getContext('2d'),
          pr = window.devicePixelRatio || 1,
          w = window.innerWidth,
          h = window.innerHeight,
          f = 90,
          q,
          m = Math,
          r = 0,
          u = m.PI*2,
          v = m.cos,
          z = m.random
      c.width = w*pr
      c.height = h*pr
      x.scale(pr, pr)
      x.globalAlpha = 0.6
      function i(){
          x.clearRect(0,0,w,h)
          q=[{x:0,y:h*.7+f},{x:0,y:h*.7-f}]
          while(q[1].x<w+f) d(q[0], q[1])
      }
      function d(i,j){   
          x.beginPath()
          x.moveTo(i.x, i.y)
          x.lineTo(j.x, j.y)
          var k = j.x + (z()*2-0.25)*f,
              n = y(j.y)
          x.lineTo(k, n)
          x.closePath()
          r-=u/-50
          x.fillStyle = '#'+(v(r)*127+128<<16 | v(r+u/3)*127+128<<8 | v(r+u/3*2)*127+128).toString(16)
          x.fill()
          q[0] = q[1]
          q[1] = {x:k,y:n}
      }
      function y(p){
          var t = p + (z()*2-1.1)*f
          return (t>h||t<0) ? y(p) : t
      }
      document.onclick = i
      document.ontouchstart = i
      i()
  </script>
</html>
